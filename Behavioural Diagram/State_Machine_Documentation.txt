Behavioral State Machine Documentation

1. Risk Assessment

Description:
This state is responsible for the autonomous analysis of the surrounding environment to identify potential structural risks that could compromise navigation or human safety. The robot continuously scans the environment using data from the RGB-D Camera, LiDAR, and SONAR sensors. If anomalies are detected, the system evaluates the risk level and logs it. In case of high risk, it sends an alert to the human operator and provides navigation with updated information to examinate critical zones.

Key Functionalities:
- Scan Environment: Continuously monitor the robot’s surroundings using sensor fusion.
- Anomaly Detection: Identify cracks, deformations, or unstable sections in real-time.
- Assess Risk Level: Classify the level of danger (e.g., Low, Medium, High) based on structural damage.
- Update Log and Send Alerts: Log observations for later analysis and send immediate alerts for critical areas.

Transitions:
- If the risk level is High: Send alert and update navigation.
- If no anomaly is detected: Resume normal operation.


2. Victim Detection and Reporting

Description:
In this state, the robot performs autonomous victim search operations. Visual and auditory data are acquired and processed to detect potential victims. Once a victim is detected and confirmed, the system assigns a unique ID, prioritises based on apparent condition, and adds the individual to the victim list. Navigation is updated to direct the robot toward the victim for further assessment.

Key Functionalities:
- Process Image: Use RGB-D Camera to analyse the visual scene for signs of human presence.
- Verify Detection: Use audio confirmation or additional sensory input to verify if the target is an actual victim.
- Check and Assign ID: If confirmed, the robot ensures the victim is not already catalogued and assigns a unique identifier (position w.r.t. an absolute reference point).
- Assign Priority: Based on initial analysis, prioritise the victim using pre-defined emergency criteria.
- Update Victim List: Store victim data for reporting and navigation decisions.

Transitions:
- If the victim is confirmed and new: Send signal to navigation and move to the victim.
- If no new victim is found: Continue exploration.
- If higher-priority victim is detected: Update the current goal.


3. Triage

Description:
Once the robot reaches a victim’s location, it initiates the triage process to assess the medical condition of the individual. This involves verbal interaction via speakers and microphones to evaluate the level of consciousness and responsiveness. Additionally, the system captures visual data to identify injuries. The collected information is processed into a medical report and sent to the human operator.

Key Functionalities:

- Ask Questions and Record Responses: The robot generates predefined questions based on the missing data on the Medical Report to assess responsiveness. Responses are captured using microphones. If the Responses of the victim are not clear or not detected, the robot tries again a few times. If the victim cannot answer correctly, then the robot sends an alert to the operator.
- Acquire and Classify Images: The RGB-D Camera captures images to visually detect injuries and classify the severity and type of injury. If the robot can't receive images in more than 10 seconds, then sends a warning.
- Update and Send Report: Information is elaborated and transformed into a structured triage report. If sufficient data is available, it is sent to the operator.
- Perform Instructions: If additional actions are requested from the operator, they are executed using the speaker module.

Transitions:
- If the triage is ended, then the robot updates the list of victims helped.
- If the robot finds an unconscious victim, then proceeds to verify the victim's condition, only scanning its external injuries and sends the report to the operator.
- If instructions are received: Execute instructions before resuming the task.



Cognitive Architecture for Robotics – Assignment 1 (2024/25)
Francesca Amato - s7827998
Gian Marco Balia - 
Shady Abdelmalek - 

Topic 1: Post-Earthquake Scenarios for Search and Rescue

This assignment aims to design a cognitive architecture for effectively managing a TIAGo robotic platform operating in post-earthquake environments. The robot is tasked with locating injured individuals, evaluating their medical conditions, and assessing the structural integrity of the surrounding environment.

To accomplish these goals, the robot is equipped with the following sensors and devices:
- RGB-D Camera
- LiDAR
- SONAR
- Force Sensors
- Microphones
- Speakers

The primary tasks addressed by our architecture include:

- Assessment of victims’ conditions: Evaluate consciousness, responsiveness, and injury severity to prioritise rescue efforts.
- Detection of structural hazards: Identify cracks, unstable sections, and other criticalities in buildings through real-time structural analysis.
- Transmission of critical reports: Send timely and detailed structural and victim status updates to a remote human supervisor.
- Mission status notification: Upon completing full area exploration, notify the operator and await further instructions.

Disaster Response Robot Architecture Diagram
The architecture is divided into subsystems, each responsible for specific components and functionalities, as outlined below:

1. Search and Rescue Task

- Victim Detection and Reporting: Detects the presence of victims using audio-visual cues. Once a victim is confirmed, an alert is sent to the operator, a priority level is assigned, and a signal is issued to the navigation system to approach the victim.

- Triage System: Interacts verbally with the victim to assess responsiveness and consciousness through predefined questions. Captures and processes responses to evaluate the victim’s condition. In critical situations, an immediate alert is transmitted to the operator.

2. Structural Analysis

- Obstacle and Damage Detection: Continuously senses obstacles and structural anomalies along the robot’s path using multi-sensor input.

- Structural Risk Assessment: Evaluates wall stability and other environmental conditions. Updates a log file and, when necessary, moves closer to hazardous areas to perform a more thorough inspection. Alerts the operator in case of critical findings.

3. Communication Interface

- Real-time Reporting: Continuously transmits environmental and victim data to human supervisors.

- Mission Status Notification: Aggregates reporting data to produce a mission status code, indicating the current operational state of the robot. Signals the completion of the mission and awaits further instructions.

- Graphical User Interface (GUI): Receives mission reports and allows the human operator to issue commands and control directives to the robot.

- Speakers and Microphones: Enable verbal interaction with victims—microphones detect responses or environmental sounds, while speakers deliver verbal instructions or inquiries.

4. Core System

- SLAM (Simultaneous Localisation and Mapping): Fuses data from LiDAR, SONAR, and RGB-D cameras to simultaneously construct a detailed 3D map of the environment and localise the robot within it.

- Autonomous Navigation: Processes navigation goals and continuously adjusts the robot’s trajectory based on updated map data and environmental changes, such as new obstacles or shifting debris.

5. Perception Subsystem

- Environmental Perception: Utilises LiDAR and RGB-D cameras to generate a 3D map of the environment, detect victims and structural damages, and collect visual data for further analysis.

- Localisation Sensors: Includes GPS for global positioning and IMUs (Inertial Measurement Units) to measure the robot’s velocity and acceleration, enhancing localization accuracy.


System Interaction Flow

- The robot continuously scans the environment using its sensors.
- Upon detecting victims or structural instabilities, the system prioritises actions based on severity and proximity.
- Real-time alerts and analytical reports are sent to a remote human supervisor.
- When the mission is completed and the full map has been explored, the robot communicates its status and awaits further instructions.
